"use client";

import React, {
  useCallback,
  useEffect,
  useRef,
  useState,
} from "react";
import {
  ensureLocalGenerator,
  generateLocalReply,
  type LocalMessage,
} from "../../llm-client/llm";
import ChatMessages from "./ChatMessages";
import QuickTopics from "./QuickTopics";
import ChatControls from "./ChatControls";
import { cleanAndConvertToHtml, toLocalHistory } from "./utils";
import { ChatMessage } from "./types";

export default function ChatbotContent() {
  const [messages, setMessages] = useState<ChatMessage[]>([
    {
      role: "assistant",
      content:
        "Salut üëã Je suis ton chatbot IA p√©dagogique. Pose une question ou clique sur un des domaines ci-dessous (Classification, LLM, etc.) pour avoir une explication simple.",
    },
  ]);
  const [input, setInput] = useState("");
  const [useCustomSystemPrompt, setUseCustomSystemPrompt] = useState(false);
  const [useLocalLlm, setUseLocalLlm] = useState(false);
  const [localModelReady, setLocalModelReady] = useState(false);
  const [localModelError, setLocalModelError] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const messagesContainerRef = useRef<HTMLDivElement | null>(null);

  const isDumbMode = useCustomSystemPrompt;

  // Scroll vers le bas quand les messages changent, mais seulement dans le conteneur
  useEffect(() => {
    if (messagesContainerRef.current) {
      messagesContainerRef.current.scrollTop = messagesContainerRef.current.scrollHeight;
    }
  }, [messages]);

  // Charge le mod√®le local (appel√© au toggle + en fallback si besoin)
  const loadLocalModel = useCallback(async () => {
    setLocalModelError(null);
    setLocalModelReady(false);
    try {
      await ensureLocalGenerator();
      setLocalModelReady(true);
    } catch (err) {
      console.error(err);
      setLocalModelError("Impossible de charger le mod√®le local.");
      // On d√©sactive le mode local si le chargement √©choue
      setUseLocalLlm(false);
      throw err;
    }
  }, []);

  const sendMessage = async (text: string) => {
    const trimmed = text.trim();
    if (!trimmed || isLoading) return;

    const userMessage: ChatMessage = { role: "user", content: trimmed };

    const nextMessages = [...messages, userMessage];

    setMessages(nextMessages);
    setInput("");
    setIsLoading(true);
    setError(null);
    setLocalModelError(null);

    try {
      if (useLocalLlm) {
        const systemPrompt = useCustomSystemPrompt
          ? "Tu es un chatbot loufoque. R√©ponds avec humour et concision."
          : "Tu es un assistant p√©dagogique. R√©ponds en fran√ßais clairement et bri√®vement.";

        const localHistory: LocalMessage[] = toLocalHistory(nextMessages);

        // generateLocalReply appelle lui-m√™me ensureLocalGenerator(),
        // mais loadLocalModel l'a d√©j√† pr√©charg√© c√¥t√© UX.
        const rawReply = await generateLocalReply(localHistory, systemPrompt);
        setLocalModelReady(true); // √Ä ce stade le mod√®le est forc√©ment pr√™t

        const htmlReply = await cleanAndConvertToHtml(rawReply);

        setMessages((prev) => [
          ...prev,
          {
            role: "assistant",
            content: htmlReply,
          },
        ]);
      } else {
        const res = await fetch("/api/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            messages: nextMessages,
            systemPromptCustom: useCustomSystemPrompt ? 1 : 0,
          }),
        });

        if (!res.ok) {
          throw new Error(`HTTP error ${res.status}`);
        }

        const data = (await res.json()) as { reply?: string } | string;

        const rawReply =
          typeof data === "string"
            ? data
            : data?.reply ??
              "Je n'ai pas r√©ussi √† comprendre la r√©ponse du serveur.";

        const htmlReply = await cleanAndConvertToHtml(rawReply);

        setMessages((prev) => [
          ...prev,
          {
            role: "assistant",
            content: htmlReply,
          },
        ]);
      }
    } catch (err) {
      console.error(err);
      setError(
        useLocalLlm
          ? "Erreur lors de la g√©n√©ration locale."
          : "Impossible de contacter le chatbot. V√©rifie que FastAPI tourne bien sur http://localhost:8001/chat."
      );
    } finally {
      setIsLoading(false);
    }
  };

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    sendMessage(input);
  };

  const handleTopicClick = (prompt: string) => {
    sendMessage(prompt);
  };

  // Quand on active le LLM local, on lance imm√©diatement le chargement du mod√®le
  const handleToggleLocalLlm = (checked: boolean) => {
    setLocalModelError(null);
    setUseLocalLlm(checked);

    if (checked) {
      // pr√©chargement non bloquant (UI voit localModelReady = false ‚Üí "charge...")
      loadLocalModel().catch(() => {
        // l'erreur est d√©j√† g√©r√©e dans loadLocalModel
      });
    } else {
      // On r√©initialise l'√©tat "pr√™t"
      setLocalModelReady(false);
    }
  };

  return (
    <div className="w-full h-fit pb-1 px-1 lg:pb-3 lg:px-3">
      <div
        className={`w-full h-full min-h-screen flex flex-col items-center justify-center py-10 px-4 rounded xl:rounded-xl relative overflow-hidden transition-colors duration-300 ${
          isDumbMode
            ? "bg-gradient-to-br from-yellow-100 via-pink-100 to-lime-100"
            : "bg-slate-100"
        }`}
      >
        <div className="w-full max-w-4xl flex flex-col gap-5">
          <header className="text-center space-y-2">
            <p className="text-3xl text-purple-400 font-bold">Chatbot Page</p>
            <p className="text-center text-slate-500 font-medium max-w-2xl mx-auto">
              Pose tes questions sur l&apos;IA ou clique sur un domaine ci-dessous
              pour que le chatbot t&apos;explique des notions comme la
              <span className="font-semibold"> classification</span>, les
              <span className="font-semibold"> LLM</span>, etc.
            </p>
          </header>

          <div
            className={`flex flex-col rounded-2xl border h-[70vh] max-h-[720px] shadow-md transition-colors duration-300 ${
              isDumbMode
                ? "bg-white/90 backdrop-blur border-amber-200 shadow-[0_15px_60px_-30px_rgba(249,115,22,0.4)]"
                : "bg-white border-slate-200"
            }`}
          >
            {/* Zone des messages */}
            <div ref={messagesContainerRef} className="flex-1 overflow-y-auto p-4 space-y-3">
              {messages.map((msg, idx) => (
                <div
                  key={idx}
                  className={`flex w-full ${
                    msg.role === "user" ? "justify-end" : "justify-start"
                  }`}
                >
                  <div
                    className={`max-w-[80%] rounded-2xl px-3 py-2 text-sm whitespace-pre-wrap border ${
                      msg.role === "user"
                        ? isDumbMode
                          ? "bg-lime-400 text-black rounded-br-none border-lime-500 shadow-sm"
                          : "bg-purple-500 text-white rounded-br-none border-purple-500"
                        : isDumbMode
                        ? "bg-gradient-to-r from-amber-50 via-pink-50 to-lime-50 text-amber-900 rounded-bl-none border-amber-200 shadow"
                        : "bg-slate-100 text-slate-800 rounded-bl-none border-slate-200"
                    }`}
                  >
                    {msg.role === "assistant" ? (
                      <div
                        className="prose prose-sm max-w-none"
                        dangerouslySetInnerHTML={{ __html: msg.content }}
                      />
                    ) : (
                      msg.content
                    )}
                  </div>
                </div>
              ))}
            </div>

            {/* Bubbles + input */}
            <div className="border-t border-slate-200 px-3 py-3 space-y-3">
              <QuickTopics
                disabled={isLoading}
                isDumbMode={isDumbMode}
                onClickTopic={handleTopicClick}
              />

              {error && (
                <p className="text-xs text-red-500" role="alert">
                  {error}
                </p>
              )}

              <ChatControls
                input={input}
                onInputChange={setInput}
                onSubmit={handleSubmit}
                isLoading={isLoading}
                isDumbMode={isDumbMode}
                useLocalLlm={useLocalLlm}
                localModelReady={localModelReady}
                onToggleLocalLlm={handleToggleLocalLlm}
                useCustomSystemPrompt={useCustomSystemPrompt}
                onToggleCustomPrompt={setUseCustomSystemPrompt}
                localModelError={localModelError}
              />
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
